{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medical Chatbot with Latest Pinecone SDK (v7+)\n",
    "This notebook demonstrates a retrieval-augmented generation (RAG) workflow using the latest Pinecone SDK, LangChain, and HuggingFace embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\t000020y\\\\OneDrive - Trench Group\\\\Desktop\\\\Project\\\\end-to-end_medical_chatbot'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set Working Directory\n",
    "import os\n",
    "os.chdir(r\"C:\\Users\\t000020y\\OneDrive - Trench Group\\Desktop\\Project\\end-to-end_medical_chatbot\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Environment Variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PDF Loaders\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define PDF Loader Function\n",
    "def load_pdf_file(data):\n",
    "    \"\"\"\n",
    "    Loads all PDF files from the specified directory using LangChain's DirectoryLoader and PyPDFLoader.\n",
    "    Args:\n",
    "        data (str): Path to the directory containing PDF files.\n",
    "    Returns:\n",
    "        list: A list of loaded document objects.\n",
    "    \"\"\"\n",
    "    loader = DirectoryLoader(data, glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "    print(f\"Loaded {len(documents)} PDF documents from {data}\")\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4505 PDF documents from data/external/\n"
     ]
    }
   ],
   "source": [
    "# Extract PDF Documents\n",
    "extracted_data = load_pdf_file(data='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Chunking Function\n",
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "    print(f\"Split into {len(text_chunks)} chunks\")\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into 40000 chunks\n"
     ]
    }
   ],
   "source": [
    "# Split text into chunks\n",
    "text_chunks = text_split(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\t000020y\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\end-to-end-medical-chatbot-aO-jUsjR-py3.12\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\t000020y\\AppData\\Local\\Temp\\ipykernel_26436\\3669196610.py:7: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "# Set Up Embeddings\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Download the Embeddings from Hugging Face\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "        model_kwargs={'device': 'cpu'},\n",
    "        encode_kwargs={'normalize_embeddings': True}\n",
    "    )\n",
    "    return embeddings\n",
    "\n",
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new index: medicalbot\n"
     ]
    }
   ],
   "source": [
    "# Initialize Pinecone with the latest SDK (v7+)\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "# Initialize Pinecone client\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "# Set index name\n",
    "index_name = 'medicalbot'\n",
    "\n",
    "# Check if index exists, create if it doesn't\n",
    "if index_name not in [index.name for index in pc.list_indexes()]:\n",
    "    # Create Pinecone index\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,  # dimension of all-MiniLM-L6-v2 embeddings\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "    )\n",
    "    print(f\"Created new index: {index_name}\")\n",
    "else:\n",
    "    print(f\"Using existing index: {index_name}\")\n",
    "\n",
    "# Get the index\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to upsert documents to Pinecone\n",
    "def upsert_to_pinecone(documents, embedding_function, batch_size=100):\n",
    "    \"\"\"\n",
    "    Upsert documents to Pinecone index.\n",
    "    Args:\n",
    "        documents: List of LangChain Document objects\n",
    "        embedding_function: Function to generate embeddings\n",
    "        batch_size: Size of batches for upserting\n",
    "    \"\"\"\n",
    "    for i in range(0, len(documents), batch_size):\n",
    "        batch = documents[i:i+batch_size]\n",
    "        # Create IDs and embed documents\n",
    "        ids = [f'doc_{i+j}' for j in range(len(batch))]\n",
    "        texts = [doc.page_content for doc in batch]\n",
    "        metadatas = [\n",
    "            {\n",
    "                'text': doc.page_content,\n",
    "                **doc.metadata\n",
    "            } \n",
    "            for doc in batch\n",
    "        ]\n",
    "        # Get embeddings\n",
    "        embeddings_batch = embedding_function.embed_documents(texts)\n",
    "        # Prepare vectors for upserting\n",
    "        vectors = [\n",
    "            {\n",
    "                'id': ids[j],\n",
    "                'values': embeddings_batch[j],\n",
    "                'metadata': metadatas[j]\n",
    "            }\n",
    "            for j in range(len(batch))\n",
    "        ]\n",
    "        # Upsert to Pinecone\n",
    "        index.upsert(vectors=vectors)\n",
    "    print(f\"Upserted {len(documents)} documents to Pinecone index '{index_name}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upserted 40000 documents to Pinecone index 'medicalbot'\n"
     ]
    }
   ],
   "source": [
    "# Upsert documents to Pinecone\n",
    "upsert_to_pinecone(text_chunks, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.retrievers import BaseRetriever\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.callbacks import CallbackManagerForRetrieverRun\n",
    "from typing import List\n",
    "\n",
    "class PineconeRetriever(BaseRetriever):\n",
    "    k: int = 3\n",
    "\n",
    "    def __init__(self, index, embedding_function, k=3, filter=None, namespace=None, **kwargs):\n",
    "        super().__init__(k=k, **kwargs)\n",
    "        self._index = index\n",
    "        self._embedding_function = embedding_function\n",
    "        self._filter = filter\n",
    "        self._namespace = namespace\n",
    "\n",
    "    def _get_relevant_documents(\n",
    "        self, query: str, *, run_manager: CallbackManagerForRetrieverRun\n",
    "    ) -> List[Document]:\n",
    "        query_embedding = self._embedding_function.embed_query(query)\n",
    "        results = self._index.query(\n",
    "            vector=query_embedding,\n",
    "            top_k=self.k,\n",
    "            include_metadata=True,\n",
    "            filter=self._filter,\n",
    "            namespace=self._namespace\n",
    "        )\n",
    "        documents = []\n",
    "        for match in results[\"matches\"]:\n",
    "            metadata = match.get(\"metadata\", {})\n",
    "            doc = Document(\n",
    "                page_content=metadata.get(\"text\", \"\"),\n",
    "                metadata={k: v for k, v in metadata.items() if k != \"text\"}\n",
    "            )\n",
    "            documents.append(doc)\n",
    "        return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'creationdate': '2006-10-16T20:19:33+02:00', 'creator': 'Adobe Acrobat 6.0', 'moddate': '2016-02-07T11:23:03+07:00', 'page': 55.0, 'page_label': '26', 'producer': 'PDFlib+PDI 6.0.3 (SunOS)', 'source': 'data\\\\external\\\\encyclopedia-of-medicine-vol-1-5-3rd-edition.pdf.pdf', 'total_pages': 4505.0}, page_content='Researchers, Inc. Reproduced by permission.)\\n26 GALE ENCYCLOPEDIA OF MEDICINE\\nAcne'), Document(metadata={'creationdate': '2006-10-16T20:19:33+02:00', 'creator': 'Adobe Acrobat 6.0', 'moddate': '2016-02-07T11:23:03+07:00', 'page': 55.0, 'page_label': '26', 'producer': 'PDFlib+PDI 6.0.3 (SunOS)', 'source': 'data\\\\external\\\\encyclopedia-of-medicine-vol-1-5-3rd-edition.pdf.pdf', 'total_pages': 4505.0}, page_content='Sebaceous follicles— A structure found within the\\nskin that houses the oil-producing glands and hair\\nfollicles, where pimples form.\\nSebum— An oily skin moisturizer produced by\\nsebaceous glands.\\nTretinoin— A drug that works by increasing the\\nturnover (death and replacement) of skin cells.\\nAcne vulgaris affecting a woman’s face. Acne is the general\\nname given to a skin disorder in which the sebaceous glands\\nbecome inflamed. (Photograph by Biophoto Associates, Photo'), Document(metadata={'creationdate': '2006-10-16T20:19:33+02:00', 'creator': 'Adobe Acrobat 6.0', 'moddate': '2016-02-07T11:23:03+07:00', 'page': 54.0, 'page_label': '25', 'producer': 'PDFlib+PDI 6.0.3 (SunOS)', 'source': 'data\\\\external\\\\encyclopedia-of-medicine-vol-1-5-3rd-edition.pdf.pdf', 'total_pages': 4505.0}, page_content='Pathological Stage and Recurrence in Radical\\nProstatectomy Cases.’’Journal of Urology (March\\n1998): 935-940.\\nNancy J. Nordenson\\nAcid reflux see Heartburn\\nAcidosis see Respiratory acidosis; Renal\\ntubular acidosis; Metabolic acidosis\\nAcne\\nDefinition\\nAcne is a common skin disease characterized by\\npimples on the face, chest, and back. It occurs when\\nthe pores of the skin become clogged with oil, dead\\nskin cells, and bacteria.\\nDescription\\nAcne vulgaris, the medical term for common acne,')]\n"
     ]
    }
   ],
   "source": [
    "# Create a retriever\n",
    "retriever = PineconeRetriever(\n",
    "    index=index,\n",
    "    embedding_function=embeddings,\n",
    "    k=3\n",
    ")\n",
    "\n",
    "# Test the retriever\n",
    "retrieved_docs = retriever.invoke(\"What is Acne?\")\n",
    "print(retrieved_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up LLM\n",
    "from langchain_openai import OpenAI\n",
    "llm = OpenAI(temperature=0.4, max_tokens=500)\n",
    "\n",
    "# Create the RAG chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use ONLY the following pieces of retrieved context to answer the question. \"\n",
    "    \"If the context does not contain information relevant to the question, respond ONLY with 'I don't know.' \"\n",
    "    \"Use three sentences maximum and keep the answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "\n",
    "# Create the question-answering chain\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Acromegaly and gigantism are both disorders caused by abnormal release of a chemical from the pituitary gland in the brain. This chemical is responsible for increased growth in bone and soft tissue, as well as other disturbances in the body. These disorders can be confirmed through tests for underactivity or overproduction of the pituitary gland. Left untreated, the disease does not worsen.\n"
     ]
    }
   ],
   "source": [
    "# Test the RAG chain\n",
    "response = rag_chain.invoke({\"input\": \"what is Acromegaly and gigantism?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I don't know.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"What is stats?\"})\n",
    "print(response[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "end-to-end-medical-chatbot-aO-jUsjR-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
